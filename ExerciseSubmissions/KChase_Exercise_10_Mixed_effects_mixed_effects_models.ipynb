{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kechase/Chase_DSPN_S25/blob/main/ExerciseSubmissions/KChase_Exercise_10_Mixed_effects_mixed_effects_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2W919d2ZXp7"
      },
      "source": [
        "# Exercise 10: Mixed effects"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Loading and formatting data 1/1\n",
        "2. Model fitting 4/4\n",
        "3. Model assessment 4/4\n",
        "4. Reflection 1/1"
      ],
      "metadata": {
        "id": "rzcghrbyVj7E"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4nOzVhyZXqK"
      },
      "source": [
        "This homework assignment is designed to give you practice fitting and interpreting mixed effects models.\n",
        "\n",
        "We will be using the **LexicalData.csv** and **Items.csv** files from the *Homework/lexDat* folder in the class GitHub repository again.\n",
        "\n",
        "This data is a subset of the [English Lexicon Project database](https://elexicon.wustl.edu/). It provides the reaction times (in milliseconds) of many subjects as they are presented with letter strings and asked to decide, as quickly and as accurately as possible, whether the letter string is a word or not. The **Items.csv** provides characteristics of the words used, namely frequency (how common is this word?) and length (how many letters?). Unlike in the previous homework, there isn't any missing data in the **LexicalData.csv** file.\n",
        "\n",
        "*Data courtesy of Balota, D.A., Yap, M.J., Cortese, M.J., Hutchison, K.A., Kessler, B., Loftis, B., Neely, J.H., Nelson, D.L., Simpson, G.B., & Treiman, R. (2007). The English Lexicon Project. Behavior Research Methods, 39, 445-459.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DsyBTB6ZXqN"
      },
      "source": [
        "---\n",
        "## 1. Loading and formatting the data (1 point)\n",
        "\n",
        "Load in data from the **LexicalData.csv** and **Items.csv** files. As in the previous homeworks, remove the commas from the reaction times and convert them from strings to numbers. Use `left_join` to add word characteristics `Length` and `Log_Freq_Hal` from **Items** to **LexicalData**.\n",
        "\n",
        "*Note: the `Freq_HAL` variable in **Items.csv** has a similar formatting issue, using string values with commas. We're not going to worry about fixing this since we're only using `Log_Freq_HAL`, which is the natural log transformation of `Freq_HAL`, in this homework.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 983
        },
        "id": "UnBVazYfZXqP",
        "outputId": "8b8c9dc2-2960-47c5-ae86-3708fd2c9648",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'Sub_ID'</li><li>'Trial'</li><li>'Type'</li><li>'D_RT'</li><li>'D_Word'</li><li>'Outlier'</li><li>'D_Zscore'</li></ol>\n"
            ],
            "text/latex": [
              "\\begin{enumerate*}\n",
              "\\item 'Sub\\_ID'\n",
              "\\item 'Trial'\n",
              "\\item 'Type'\n",
              "\\item 'D\\_RT'\n",
              "\\item 'D\\_Word'\n",
              "\\item 'Outlier'\n",
              "\\item 'D\\_Zscore'\n",
              "\\end{enumerate*}\n"
            ],
            "text/markdown": [
              "1. 'Sub_ID'\n",
              "2. 'Trial'\n",
              "3. 'Type'\n",
              "4. 'D_RT'\n",
              "5. 'D_Word'\n",
              "6. 'Outlier'\n",
              "7. 'D_Zscore'\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "[1] \"Sub_ID\"   \"Trial\"    \"Type\"     \"D_RT\"     \"D_Word\"   \"Outlier\"  \"D_Zscore\""
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'Occurrences'</li><li>'Word'</li><li>'Length'</li><li>'Freq_HAL'</li><li>'Log_Freq_HAL'</li></ol>\n"
            ],
            "text/latex": [
              "\\begin{enumerate*}\n",
              "\\item 'Occurrences'\n",
              "\\item 'Word'\n",
              "\\item 'Length'\n",
              "\\item 'Freq\\_HAL'\n",
              "\\item 'Log\\_Freq\\_HAL'\n",
              "\\end{enumerate*}\n"
            ],
            "text/markdown": [
              "1. 'Occurrences'\n",
              "2. 'Word'\n",
              "3. 'Length'\n",
              "4. 'Freq_HAL'\n",
              "5. 'Log_Freq_HAL'\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "[1] \"Occurrences\"  \"Word\"         \"Length\"       \"Freq_HAL\"     \"Log_Freq_HAL\""
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 6 × 9</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>Sub_ID</th><th scope=col>Trial</th><th scope=col>Type</th><th scope=col>D_RT</th><th scope=col>D_Word</th><th scope=col>Outlier</th><th scope=col>D_Zscore</th><th scope=col>Length</th><th scope=col>Log_Freq_HAL</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>157</td><td>1</td><td>1</td><td> 710</td><td>browse     </td><td>false</td><td>-0.437</td><td> 6</td><td>8.856</td></tr>\n",
              "\t<tr><th scope=row>2</th><td> 67</td><td>1</td><td>1</td><td>1094</td><td>refrigerant</td><td>false</td><td> 0.825</td><td>11</td><td>4.644</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>120</td><td>1</td><td>1</td><td> 587</td><td>gaining    </td><td>false</td><td>-0.645</td><td> 7</td><td>8.304</td></tr>\n",
              "\t<tr><th scope=row>4</th><td> 21</td><td>1</td><td>1</td><td> 984</td><td>cheerless  </td><td>false</td><td> 0.025</td><td> 9</td><td>2.639</td></tr>\n",
              "\t<tr><th scope=row>5</th><td>236</td><td>1</td><td>1</td><td> 577</td><td>pattered   </td><td>false</td><td>-0.763</td><td> 8</td><td>1.386</td></tr>\n",
              "\t<tr><th scope=row>6</th><td>236</td><td>2</td><td>1</td><td> 715</td><td>conjures   </td><td>false</td><td>-0.364</td><td> 8</td><td>5.268</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": [
              "A data.frame: 6 × 9\n",
              "\\begin{tabular}{r|lllllllll}\n",
              "  & Sub\\_ID & Trial & Type & D\\_RT & D\\_Word & Outlier & D\\_Zscore & Length & Log\\_Freq\\_HAL\\\\\n",
              "  & <int> & <int> & <int> & <dbl> & <chr> & <chr> & <dbl> & <int> & <dbl>\\\\\n",
              "\\hline\n",
              "\t1 & 157 & 1 & 1 &  710 & browse      & false & -0.437 &  6 & 8.856\\\\\n",
              "\t2 &  67 & 1 & 1 & 1094 & refrigerant & false &  0.825 & 11 & 4.644\\\\\n",
              "\t3 & 120 & 1 & 1 &  587 & gaining     & false & -0.645 &  7 & 8.304\\\\\n",
              "\t4 &  21 & 1 & 1 &  984 & cheerless   & false &  0.025 &  9 & 2.639\\\\\n",
              "\t5 & 236 & 1 & 1 &  577 & pattered    & false & -0.763 &  8 & 1.386\\\\\n",
              "\t6 & 236 & 2 & 1 &  715 & conjures    & false & -0.364 &  8 & 5.268\\\\\n",
              "\\end{tabular}\n"
            ],
            "text/markdown": [
              "\n",
              "A data.frame: 6 × 9\n",
              "\n",
              "| <!--/--> | Sub_ID &lt;int&gt; | Trial &lt;int&gt; | Type &lt;int&gt; | D_RT &lt;dbl&gt; | D_Word &lt;chr&gt; | Outlier &lt;chr&gt; | D_Zscore &lt;dbl&gt; | Length &lt;int&gt; | Log_Freq_HAL &lt;dbl&gt; |\n",
              "|---|---|---|---|---|---|---|---|---|---|\n",
              "| 1 | 157 | 1 | 1 |  710 | browse      | false | -0.437 |  6 | 8.856 |\n",
              "| 2 |  67 | 1 | 1 | 1094 | refrigerant | false |  0.825 | 11 | 4.644 |\n",
              "| 3 | 120 | 1 | 1 |  587 | gaining     | false | -0.645 |  7 | 8.304 |\n",
              "| 4 |  21 | 1 | 1 |  984 | cheerless   | false |  0.025 |  9 | 2.639 |\n",
              "| 5 | 236 | 1 | 1 |  577 | pattered    | false | -0.763 |  8 | 1.386 |\n",
              "| 6 | 236 | 2 | 1 |  715 | conjures    | false | -0.364 |  8 | 5.268 |\n",
              "\n"
            ],
            "text/plain": [
              "  Sub_ID Trial Type D_RT D_Word      Outlier D_Zscore Length Log_Freq_HAL\n",
              "1 157    1     1     710 browse      false   -0.437    6     8.856       \n",
              "2  67    1     1    1094 refrigerant false    0.825   11     4.644       \n",
              "3 120    1     1     587 gaining     false   -0.645    7     8.304       \n",
              "4  21    1     1     984 cheerless   false    0.025    9     2.639       \n",
              "5 236    1     1     577 pattered    false   -0.763    8     1.386       \n",
              "6 236    2     1     715 conjures    false   -0.364    8     5.268       "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# Load the packages\n",
        "library(tidyverse)\n",
        "library(dplyr)\n",
        "\n",
        "# Load the data\n",
        "lex_data <<- read.csv(\"/Users/katie/Documents/workspace/Data-Science-for-Psychology-and-Neuro/Homework-Datasets/lex_data/LexicalData.csv\")\n",
        "items <<- read.csv(\"/Users/katie/Documents/workspace/Data-Science-for-Psychology-and-Neuro/Homework-Datasets/lex_data/Items.csv\")\n",
        "\n",
        "# Check column names\n",
        "colnames(lex_data)\n",
        "colnames(items)\n",
        "\n",
        "# Remove commas from D_RT and convert to numeric\n",
        "lex_data$D_RT <- as.numeric(gsub(',', '', lex_data$D_RT))\n",
        "\n",
        "# Select relevant columns from items\n",
        "items <- items %>%\n",
        "  select(Word, Length, Log_Freq_HAL)\n",
        "\n",
        "# Join datasets\n",
        "word_data <- left_join(lex_data, items, by = c(\"D_Word\" = \"Word\"))\n",
        "\n",
        "# Check the result\n",
        "head(word_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXy81Viishk1"
      },
      "source": [
        "---\n",
        "## 2. Model fitting (4 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7_gEgkbzFtU"
      },
      "source": [
        "First, fit a linear model with `Log_Freq_HAL` and `Length` as predictors, and `D_RT` as the output. Include an interaction term. Use `summary()` to look at the model output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "OIOIg-GRz4rN",
        "outputId": "bd738fed-75b6-45cf-9f37-ec36984379f4",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm(formula = D_RT ~ Log_Freq_HAL * Length, data = word_data)\n",
              "\n",
              "Residuals:\n",
              "     Min       1Q   Median       3Q      Max \n",
              "-1118.01  -205.23   -86.95    90.77  3147.07 \n",
              "\n",
              "Coefficients:\n",
              "                    Estimate Std. Error t value Pr(>|t|)    \n",
              "(Intercept)         610.1903    14.6678  41.601  < 2e-16 ***\n",
              "Log_Freq_HAL         -6.0239     1.9678  -3.061  0.00221 ** \n",
              "Length               47.7531     1.6368  29.175  < 2e-16 ***\n",
              "Log_Freq_HAL:Length  -2.9421     0.2348 -12.528  < 2e-16 ***\n",
              "---\n",
              "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
              "\n",
              "Residual standard error: 359.1 on 62606 degrees of freedom\n",
              "Multiple R-squared:  0.09473,\tAdjusted R-squared:  0.09469 \n",
              "F-statistic:  2184 on 3 and 62606 DF,  p-value: < 2.2e-16\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Fit linear model with interaction term\n",
        "model <- lm(D_RT ~ Log_Freq_HAL * Length, data = word_data)\n",
        "\n",
        "# View model summary\n",
        "summary(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pbeg_JrS3mwU"
      },
      "source": [
        "Now, install `lme4` using `install.packages()` and then load the library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFSnvvb_re2O",
        "vscode": {
          "languageId": "r"
        },
        "outputId": "92614dc1-66bd-428f-9817-0364bc0ede39"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Updating HTML index of packages in '.Library'\n",
            "\n",
            "Making 'packages.html' ...\n",
            " done\n",
            "\n"
          ]
        }
      ],
      "source": [
        "install.packages(\"nlme\")\n",
        "library(nlme)\n",
        "\n",
        "# I'm working in VSCode and there is a dependency issue with lme4 that I can't resolve.\n",
        "# I tried switching to Colab but I can't get the data to load there either.\n",
        "# I'm not sure what to do about this so, after 2+ hours of troubleshooting,\n",
        "# I'm using a different, older mixed-effect model library that successfully loads on my computer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZJns7xr41nW"
      },
      "source": [
        "Now fit a mixed effects model that includes the same predictors as the linear model above, as well as random intercepts for `Sub_ID` (i.e., cases where subject ID shifts the RT mean). Use `summary()` to look at the model output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kjwT0je57N7",
        "vscode": {
          "languageId": "r"
        },
        "outputId": "4cc2de09-916c-49c2-a6ad-dea63504fa7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Linear mixed-effects model fit by REML\n",
              "  Data: word_data \n",
              "       AIC      BIC    logLik\n",
              "  888475.9 888521.1 -444232.9\n",
              "\n",
              "Random effects:\n",
              " Formula: ~1 | Sub_ID\n",
              "        (Intercept) Residual\n",
              "StdDev:    215.2961 288.5925\n",
              "\n",
              "Fixed effects:  D_RT ~ Length + Log_Freq_HAL \n",
              "                Value Std.Error    DF   t-value p-value\n",
              "(Intercept)  769.0765 13.950437 62309  55.12921       0\n",
              "Length        29.2257  0.506013 62309  57.75681       0\n",
              "Log_Freq_HAL -30.1567  0.533005 62309 -56.57870       0\n",
              " Correlation: \n",
              "             (Intr) Length\n",
              "Length       -0.379       \n",
              "Log_Freq_HAL -0.352  0.365\n",
              "\n",
              "Standardized Within-Group Residuals:\n",
              "       Min         Q1        Med         Q3        Max \n",
              "-4.4812554 -0.5550896 -0.1608760  0.3131659 10.7065695 \n",
              "\n",
              "Number of Observations: 62610\n",
              "Number of Groups: 299 "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Fit mixed effects model with random intercepts for Subject ID using nlme\n",
        "mixed_model_alt <- lme(D_RT ~ Length + Log_Freq_HAL, random = ~1|Sub_ID, data = word_data)\n",
        "\n",
        "# View the model summary\n",
        "summary(mixed_model_alt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vfb_ovk7JFGt"
      },
      "source": [
        "---\n",
        "## 3. Model assessment (4 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7B1Ux6RHGjy"
      },
      "source": [
        "Compare the three t-values for the fixed effects and the mixed effects models. How do they differ, and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCi5gYOeHo6m"
      },
      "source": [
        "> *In the linear model, Length had a t-value of 29.175, Log_Freq_HAL: -3.061 and the Interaction (Log_Freq_HAL): -12.528. In the mixed effects model, Length had a t-value of 57.75681, Log_Freq_HAL: -56.57870. In both cases the Length has a positive effect and Log_Freq_HAL a negative effect, but the mixed effects model makes each of those impacts bigger (in their respective directions). The mixed effects model is accounting for fixed & random effects by taking into account within-subjects study designs in a way that the linear model isn't designed to do. *\n",
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hukKG1AbGqXM"
      },
      "source": [
        "Use the Aikeke Information Criterion (AIC) to compare these two models. Which one is better?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMDg8qb5FhJz",
        "vscode": {
          "languageId": "r"
        },
        "outputId": "e102390c-34ca-4ce9-a0a2-d6cd815ad1f9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message in AIC.default(model, mixed_model_alt):\n",
            "“models are not all fitted to the same number of observations”\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 2 × 2</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>df</th><th scope=col>AIC</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>model</th><td>5</td><td>914436.4</td></tr>\n",
              "\t<tr><th scope=row>mixed_model_alt</th><td>5</td><td>888475.9</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": [
              "A data.frame: 2 × 2\n",
              "\\begin{tabular}{r|ll}\n",
              "  & df & AIC\\\\\n",
              "  & <dbl> & <dbl>\\\\\n",
              "\\hline\n",
              "\tmodel & 5 & 914436.4\\\\\n",
              "\tmixed\\_model\\_alt & 5 & 888475.9\\\\\n",
              "\\end{tabular}\n"
            ],
            "text/markdown": [
              "\n",
              "A data.frame: 2 × 2\n",
              "\n",
              "| <!--/--> | df &lt;dbl&gt; | AIC &lt;dbl&gt; |\n",
              "|---|---|---|\n",
              "| model | 5 | 914436.4 |\n",
              "| mixed_model_alt | 5 | 888475.9 |\n",
              "\n"
            ],
            "text/plain": [
              "                df AIC     \n",
              "model           5  914436.4\n",
              "mixed_model_alt 5  888475.9"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "-25960.524378507"
            ],
            "text/latex": [
              "-25960.524378507"
            ],
            "text/markdown": [
              "-25960.524378507"
            ],
            "text/plain": [
              "[1] -25960.52"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ic = AIC(model, mixed_model_alt)\n",
        "ic\n",
        "diff(ic$AIC)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4oTfsYmIvYt"
      },
      "source": [
        "> *The mixed model has a lower AIC and is a better fit model. The mixed-effects model accounts for more variance than the simple linear model, even after accounting for increased complexity.*\n",
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARF2PF2yLXkZ"
      },
      "source": [
        "---\n",
        "##  4. Reflection (1 point)\n",
        "\n",
        "What other random effects could be controlled for in this data set?\n",
        "\n",
        "> *Maybe you could take into account the change in responses, over time, for the same word or same length of word. I'm running a 100 trial experiment right now and aware that fatigue may be an issue; maybe here, too. *\n",
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4MPECMmZXqe"
      },
      "source": [
        "**DUE:** 5pm EST, March 18, 2024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        },
        "id": "1daYzw2wU00D"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9GUofXN4BVy"
      },
      "source": [
        "**IMPORTANT** Did you collaborate with anyone on this assignment? If so, list their names here.\n",
        "> *As always, working with tutor, claude.ai*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.2.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}